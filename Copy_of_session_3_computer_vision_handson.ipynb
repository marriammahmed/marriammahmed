{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marriammahmed/marriammahmed/blob/main/Copy_of_session_3_computer_vision_handson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w-fcQ933IRk"
      },
      "source": [
        "# Session 3: Computer Vision - Working Code Templates\n",
        "\n",
        "**Course:** Engineering Teamwork III: AI and Autonomous Systems Lab  \n",
        "**Instructor:** Ruthra Bellan, M.Sc.  \n",
        "\n",
        "---\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "**Before starting:**\n",
        "1. Make sure you have a test road image ready\n",
        "2. Work through each template in order\n",
        "3. Don't skip cells - run them sequentially!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avDz62Oy3IRl"
      },
      "source": [
        "## Template 1: Setup and Image Upload (5 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTv5Ew-T3IRl"
      },
      "outputs": [],
      "source": [
        "# Install and Import Libraries\n",
        "# OpenCV is pre-installed in Colab, but we'll verify\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow  # Special for Colab!\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbMvZcXe3IRm"
      },
      "outputs": [],
      "source": [
        "# Upload Test Image\n",
        "print(\"Click 'Choose Files' below and select your test road image\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Uploaded: {filename}\")\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imdecode(np.frombuffer(uploaded[filename], np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "if img is None:\n",
        "    print(\"‚ùå ERROR: Could not load image!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Image loaded successfully!\")\n",
        "    print(f\"   Shape: {img.shape}\")\n",
        "    print(f\"   Size: {img.shape[1]}x{img.shape[0]} pixels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTWrzFpA3IRm"
      },
      "outputs": [],
      "source": [
        "# Display Image Function for Colab\n",
        "def show_image(img, title=\"Image\"):\n",
        "    \"\"\"Display image in Colab (handles BGR to RGB conversion)\"\"\"\n",
        "    if img is None:\n",
        "        print(\"‚ùå Error: Image is None\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    if len(img.shape) == 3:\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img_rgb)\n",
        "    else:\n",
        "        plt.imshow(img, cmap='gray')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Test it\n",
        "show_image(img, \"Original Image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gExHq7J3IRm"
      },
      "source": [
        "---\n",
        "## Template 2: Hands-On 1 - Load & Explore Images (30 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjiZlhH13IRm"
      },
      "outputs": [],
      "source": [
        "# Basic Image Operations\n",
        "\n",
        "# Check if image loaded\n",
        "if img is None:\n",
        "    print(\"‚ùå ERROR: No image loaded! Upload one first.\")\n",
        "else:\n",
        "    print(\"‚úÖ Image Analysis:\")\n",
        "    print(f\"   Dimensions: {img.shape[1]}x{img.shape[0]}\")\n",
        "    print(f\"   Channels: {img.shape[2] if len(img.shape) == 3 else 1}\")\n",
        "    print(f\"   Data type: {img.dtype}\")\n",
        "    print(f\"   Total pixels: {img.size}\")\n",
        "\n",
        "    # Display original\n",
        "    show_image(img, \"Original Image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re_JRVnY3IRn"
      },
      "outputs": [],
      "source": [
        "# Convert to Grayscale\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Verify conversion\n",
        "if gray is None or len(gray.shape) != 2:\n",
        "    print(\"‚ùå ERROR: Grayscale conversion failed!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Grayscale conversion successful!\")\n",
        "    print(f\"   Shape: {gray.shape}\")\n",
        "    print(f\"   Min value: {gray.min()}, Max value: {gray.max()}\")\n",
        "\n",
        "    # Display\n",
        "    show_image(gray, \"Grayscale Image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-c5PDuN3IRn"
      },
      "outputs": [],
      "source": [
        "# Convert to HSV\n",
        "\n",
        "# Convert to HSV\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "print(f\"‚úÖ HSV conversion successful!\")\n",
        "print(f\"   Shape: {hsv.shape}\")\n",
        "\n",
        "# Display all three side by side\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "axes[0].set_title('Original (BGR‚ÜíRGB)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(gray, cmap='gray')\n",
        "axes[1].set_title('Grayscale')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Show RAW HSV - looks weird!\n",
        "axes[2].imshow(hsv)\n",
        "axes[2].set_title('HSV (raw - looks strange!)')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrf7K5qQ3IRn"
      },
      "outputs": [],
      "source": [
        "# Inspect Pixels\n",
        "\n",
        "# Get image dimensions\n",
        "height, width = gray.shape\n",
        "\n",
        "# Access center pixel\n",
        "center_row, center_col = height//2, width//2\n",
        "center_pixel_bgr = img[center_row, center_col]\n",
        "center_pixel_gray = gray[center_row, center_col]\n",
        "\n",
        "print(f\"Center pixel location: ({center_col}, {center_row})\")\n",
        "print(f\"BGR value: {center_pixel_bgr}\")\n",
        "print(f\"Grayscale value: {center_pixel_gray}\")\n",
        "\n",
        "# Access a region\n",
        "region = img[100:200, 150:250]\n",
        "print(f\"\\nRegion (rows 100-200, cols 150-250):\")\n",
        "print(f\"   Shape: {region.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Lyiy6W3IRn"
      },
      "source": [
        "---\n",
        "## Template 3: Hands-On 2 - Edge Detection (40 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJGiasLa3IRn"
      },
      "outputs": [],
      "source": [
        "# Basic Edge Detection with Recommended Parameters\n",
        "\n",
        "# Use recommended starting parameters\n",
        "blur_kernel = (5, 5)\n",
        "threshold1 = 50\n",
        "threshold2 = 150\n",
        "\n",
        "# Apply Gaussian blur\n",
        "blurred = cv2.GaussianBlur(gray, blur_kernel, 0)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "edges = cv2.Canny(blurred, threshold1, threshold2)\n",
        "\n",
        "# Check results\n",
        "edge_pixels = np.sum(edges > 0)\n",
        "total_pixels = edges.shape[0] * edges.shape[1]\n",
        "edge_percent = (edge_pixels / total_pixels) * 100\n",
        "\n",
        "print(f\"‚úÖ Edge Detection Complete!\")\n",
        "print(f\"   Edge pixels: {edge_pixels} ({edge_percent:.2f}%)\")\n",
        "print(f\"   Parameters: blur={blur_kernel}, Canny=({threshold1}, {threshold2})\")\n",
        "\n",
        "# Display results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "axes[0, 0].set_title('1. Original Image')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(gray, cmap='gray')\n",
        "axes[0, 1].set_title('2. Grayscale')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[1, 0].imshow(blurred, cmap='gray')\n",
        "axes[1, 0].set_title('3. Blurred')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(edges, cmap='gray')\n",
        "axes[1, 1].set_title('4. Edges Detected')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVU61a0I3IRn"
      },
      "outputs": [],
      "source": [
        "# Test Different Parameter Sets (from cheat sheet)\n",
        "\n",
        "# Test three recommended parameter sets\n",
        "parameter_sets = {\n",
        "    \"Normal lighting (START HERE)\": (50, 150),\n",
        "    \"Bright/high contrast\": (80, 200),\n",
        "    \"Low contrast/shadows\": (30, 90)\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for idx, (name, (low, high)) in enumerate(parameter_sets.items()):\n",
        "    # Apply Canny with different thresholds\n",
        "    test_edges = cv2.Canny(blurred, low, high)\n",
        "\n",
        "    # Count edge pixels\n",
        "    edge_count = np.sum(test_edges > 0)\n",
        "    edge_pct = (edge_count / total_pixels) * 100\n",
        "\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Thresholds: ({low}, {high})\")\n",
        "    print(f\"  Edge pixels: {edge_count} ({edge_pct:.2f}%)\")\n",
        "    print()\n",
        "\n",
        "    # Display\n",
        "    axes[idx].imshow(test_edges, cmap='gray')\n",
        "    axes[idx].set_title(f'{name}\\n({low}, {high})\\n{edge_pct:.1f}% edges')\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üëÜ Which parameter set works best for YOUR image?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvfwOQy_3IRn"
      },
      "outputs": [],
      "source": [
        "# Fine-Tune Your Parameters\n",
        "\n",
        "# ADJUST THESE VALUES based on what worked above\n",
        "my_threshold1 = 50   # ‚Üê Change this\n",
        "my_threshold2 = 150  # ‚Üê Change this\n",
        "my_blur_kernel = (5, 5)  # ‚Üê Change if needed\n",
        "\n",
        "# Apply your tuned parameters\n",
        "blurred_tuned = cv2.GaussianBlur(gray, my_blur_kernel, 0)\n",
        "edges_tuned = cv2.Canny(blurred_tuned, my_threshold1, my_threshold2)\n",
        "\n",
        "# Check results\n",
        "edge_pixels_tuned = np.sum(edges_tuned > 0)\n",
        "edge_percent_tuned = (edge_pixels_tuned / total_pixels) * 100\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"MY WORKING PARAMETERS:\")\n",
        "print(f\"  Blur kernel: {my_blur_kernel}\")\n",
        "print(f\"  Canny thresholds: ({my_threshold1}, {my_threshold2})\")\n",
        "print(f\"  Result: {edge_pixels_tuned} edge pixels ({edge_percent_tuned:.2f}%)\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nüí° Save these values! You'll need them for the next exercise.\")\n",
        "\n",
        "# Display\n",
        "show_image(edges_tuned, \"My Tuned Edge Detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh6r3fHe3IRo"
      },
      "source": [
        "---\n",
        "## Template 4: Hands-On 3 - Complete Lane Detector (50 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4crC1GKd3IRo"
      },
      "outputs": [],
      "source": [
        "# Region of Interest (ROI) Function\n",
        "\n",
        "def region_of_interest(img, vertices):\n",
        "    \"\"\"Apply ROI mask to image\"\"\"\n",
        "    # Create black mask\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    # Fill ROI area with white\n",
        "    cv2.fillPoly(mask, vertices, 255)\n",
        "\n",
        "    # Keep only ROI area\n",
        "    masked_img = cv2.bitwise_and(img, mask)\n",
        "\n",
        "    return masked_img\n",
        "\n",
        "# Define ROI vertices (ADJUST FOR YOUR IMAGE!)\n",
        "height, width = edges_tuned.shape\n",
        "\n",
        "vertices = np.array([[\n",
        "    (0, height),                          # Bottom left\n",
        "    (width//2 - 50, height//2 + 50),     # Top left\n",
        "    (width//2 + 50, height//2 + 50),     # Top right\n",
        "    (width, height)                       # Bottom right\n",
        "]], dtype=np.int32)\n",
        "\n",
        "# Apply ROI\n",
        "roi_edges = region_of_interest(edges_tuned, vertices)\n",
        "\n",
        "# Visualize ROI on original image\n",
        "img_with_roi = img.copy()\n",
        "cv2.polylines(img_with_roi, vertices, True, (255, 0, 0), 3)\n",
        "\n",
        "# Display\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "axes[0].imshow(cv2.cvtColor(img_with_roi, cv2.COLOR_BGR2RGB))\n",
        "axes[0].set_title('ROI Overlay (blue trapezoid)')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(edges_tuned, cmap='gray')\n",
        "axes[1].set_title('Original Edges')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(roi_edges, cmap='gray')\n",
        "axes[2].set_title('ROI Edges Only')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Does the ROI (blue trapezoid) cover the road area correctly?\")\n",
        "print(\"   If not, adjust the vertices values above and re-run this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNVxJ4kW3IRo"
      },
      "outputs": [],
      "source": [
        "# Line Detection Functions\n",
        "\n",
        "def detect_lines(edges):\n",
        "    \"\"\"Detect lines using Hough transform\"\"\"\n",
        "    lines = cv2.HoughLinesP(\n",
        "        edges,\n",
        "        rho=1,\n",
        "        theta=np.pi/180,\n",
        "        threshold=50,           # Adjust if needed\n",
        "        minLineLength=40,       # Adjust if needed\n",
        "        maxLineGap=100          # Adjust if needed\n",
        "    )\n",
        "    return lines\n",
        "\n",
        "def draw_lines(img, lines):\n",
        "    \"\"\"Draw detected lines on image\"\"\"\n",
        "    # Create blank image for lines\n",
        "    line_img = np.zeros_like(img)\n",
        "\n",
        "    if lines is None:\n",
        "        print(\"‚ö†Ô∏è WARNING: No lines detected!\")\n",
        "        return line_img\n",
        "\n",
        "    print(f\"‚úÖ Detected {len(lines)} lines\")\n",
        "\n",
        "    # Draw each line\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        cv2.line(line_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    return line_img\n",
        "\n",
        "# Detect lines\n",
        "lines = detect_lines(roi_edges)\n",
        "\n",
        "# Draw lines\n",
        "line_img = draw_lines(img, lines)\n",
        "\n",
        "# Combine with original image\n",
        "result = cv2.addWeighted(img, 0.8, line_img, 1, 0)\n",
        "\n",
        "# Display\n",
        "show_image(result, \"Lane Detection Result\")\n",
        "\n",
        "if lines is None:\n",
        "    print(\"\\n‚ùå No lines detected! Try:\")\n",
        "    print(\"   1. Lower Canny thresholds\")\n",
        "    print(\"   2. Adjust ROI to cover lanes\")\n",
        "    print(\"   3. Lower Hough threshold parameter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR1ksBeR3IRo"
      },
      "outputs": [],
      "source": [
        "# Complete Pipeline Function\n",
        "\n",
        "def lane_detection_pipeline(image,\n",
        "                            blur_kernel=(5, 5),\n",
        "                            canny_low=50,\n",
        "                            canny_high=150,\n",
        "                            hough_threshold=50,\n",
        "                            min_line_length=40,\n",
        "                            max_line_gap=100):\n",
        "    \"\"\"\n",
        "    Complete lane detection pipeline with configurable parameters\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    image : numpy array\n",
        "        Input BGR image\n",
        "    blur_kernel : tuple\n",
        "        Gaussian blur kernel size (must be odd numbers)\n",
        "    canny_low : int\n",
        "        Lower threshold for Canny edge detection\n",
        "    canny_high : int\n",
        "        Upper threshold for Canny edge detection\n",
        "    hough_threshold : int\n",
        "        Minimum votes for Hough line detection\n",
        "    min_line_length : int\n",
        "        Minimum line length in pixels\n",
        "    max_line_gap : int\n",
        "        Maximum gap between line segments\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    result : numpy array\n",
        "        Image with detected lanes drawn\n",
        "    \"\"\"\n",
        "\n",
        "    # Validate input\n",
        "    if image is None:\n",
        "        print(\"‚ùå ERROR: Invalid image input!\")\n",
        "        return None\n",
        "\n",
        "    # 1. Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 2. Apply Gaussian blur\n",
        "    blur = cv2.GaussianBlur(gray, blur_kernel, 0)\n",
        "\n",
        "    # 3. Canny edge detection\n",
        "    edges = cv2.Canny(blur, canny_low, canny_high)\n",
        "\n",
        "    # 4. Define ROI\n",
        "    height, width = edges.shape\n",
        "    vertices = np.array([[\n",
        "        (0, height),\n",
        "        (width//2 - 50, height//2 + 50),\n",
        "        (width//2 + 50, height//2 + 50),\n",
        "        (width, height)\n",
        "    ]], dtype=np.int32)\n",
        "\n",
        "    # 5. Apply ROI\n",
        "    roi_edges = region_of_interest(edges, vertices)\n",
        "\n",
        "    # 6. Detect lines\n",
        "    lines = cv2.HoughLinesP(\n",
        "        roi_edges,\n",
        "        rho=1,\n",
        "        theta=np.pi/180,\n",
        "        threshold=hough_threshold,\n",
        "        minLineLength=min_line_length,\n",
        "        maxLineGap=max_line_gap\n",
        "    )\n",
        "\n",
        "    # 7. Draw lines\n",
        "    line_img = draw_lines(image, lines)\n",
        "\n",
        "    # 8. Combine with original\n",
        "    result = cv2.addWeighted(image, 0.8, line_img, 1, 0)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Test with your tuned parameters\n",
        "result = lane_detection_pipeline(\n",
        "    img,\n",
        "    blur_kernel=(5, 5),\n",
        "    canny_low=my_threshold1,      # Use your values from earlier!\n",
        "    canny_high=my_threshold2,\n",
        "    hough_threshold=50,\n",
        "    min_line_length=40,\n",
        "    max_line_gap=100\n",
        ")\n",
        "\n",
        "if result is not None:\n",
        "    show_image(result, \"Complete Lane Detection Pipeline\")\n",
        "    print(\"‚úÖ Pipeline complete!\")\n",
        "else:\n",
        "    print(\"‚ùå Pipeline failed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo0XE15r3IRo"
      },
      "source": [
        "---\n",
        "## Template 5: Debugging Helpers for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoV1vvp53IRo"
      },
      "outputs": [],
      "source": [
        "# Visual Debugging - Show All Steps\n",
        "\n",
        "def debug_pipeline(image):\n",
        "    \"\"\"Show all pipeline steps for debugging\"\"\"\n",
        "\n",
        "    # Process image\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blur, my_threshold1, my_threshold2)\n",
        "\n",
        "    height, width = edges.shape\n",
        "    vertices = np.array([[\n",
        "        (0, height),\n",
        "        (width//2 - 50, height//2 + 50),\n",
        "        (width//2 + 50, height//2 + 50),\n",
        "        (width, height)\n",
        "    ]], dtype=np.int32)\n",
        "    roi_edges = region_of_interest(edges, vertices)\n",
        "\n",
        "    lines = detect_lines(roi_edges)\n",
        "    line_img = draw_lines(image, lines)\n",
        "    result = cv2.addWeighted(image, 0.8, line_img, 1, 0)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    axes[0, 0].set_title('1. Original')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    axes[0, 1].imshow(gray, cmap='gray')\n",
        "    axes[0, 1].set_title('2. Grayscale')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(blur, cmap='gray')\n",
        "    axes[0, 2].set_title('3. Blurred')\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    axes[1, 0].imshow(edges, cmap='gray')\n",
        "    axes[1, 0].set_title('4. Edges')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    axes[1, 1].imshow(roi_edges, cmap='gray')\n",
        "    axes[1, 1].set_title('5. ROI Edges')\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    axes[1, 2].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "    axes[1, 2].set_title('6. Final Result')\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"=\" * 50)\n",
        "    print(\"PIPELINE STATISTICS:\")\n",
        "    print(f\"  Original size: {image.shape}\")\n",
        "    print(f\"  Edge pixels: {np.sum(edges > 0)}\")\n",
        "    print(f\"  ROI edge pixels: {np.sum(roi_edges > 0)}\")\n",
        "    print(f\"  Lines detected: {len(lines) if lines is not None else 0}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# Run debug visualization\n",
        "debug_pipeline(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSo3Ahiq3IRo"
      },
      "outputs": [],
      "source": [
        "# Parameter Exploration Tool\n",
        "\n",
        "def explore_parameters(image, param_name, param_values):\n",
        "    \"\"\"\n",
        "    Test different parameter values side-by-side\n",
        "\n",
        "    param_name: 'canny_low', 'canny_high', 'hough_threshold', etc.\n",
        "    param_values: list of values to test\n",
        "    \"\"\"\n",
        "\n",
        "    num_tests = len(param_values)\n",
        "    fig, axes = plt.subplots(1, num_tests, figsize=(6*num_tests, 6))\n",
        "\n",
        "    if num_tests == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx, value in enumerate(param_values):\n",
        "        # Set parameters\n",
        "        params = {\n",
        "            'blur_kernel': (5, 5),\n",
        "            'canny_low': my_threshold1,\n",
        "            'canny_high': my_threshold2,\n",
        "            'hough_threshold': 50,\n",
        "            'min_line_length': 40,\n",
        "            'max_line_gap': 100\n",
        "        }\n",
        "\n",
        "        # Update the parameter being tested\n",
        "        params[param_name] = value\n",
        "\n",
        "        # Run pipeline\n",
        "        result = lane_detection_pipeline(image, **params)\n",
        "\n",
        "        # Display\n",
        "        if result is not None:\n",
        "            axes[idx].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "            axes[idx].set_title(f'{param_name} = {value}')\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example: Test different Canny lower thresholds\n",
        "print(\"Testing different Canny lower thresholds:\")\n",
        "explore_parameters(img, 'canny_low', [30, 50, 80])\n",
        "\n",
        "# Example: Test different Hough thresholds\n",
        "print(\"\\nTesting different Hough thresholds:\")\n",
        "explore_parameters(img, 'hough_threshold', [30, 50, 70, 100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KANpCLZ3IRp"
      },
      "outputs": [],
      "source": [
        "# Error Checker\n",
        "\n",
        "def check_pipeline_health(image):\n",
        "    \"\"\"Run diagnostics on the pipeline\"\"\"\n",
        "\n",
        "    print(\"üîç PIPELINE DIAGNOSTICS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Check 1: Image loaded\n",
        "    if image is None:\n",
        "        print(\"‚ùå FAIL: Image is None\")\n",
        "        return\n",
        "    print(\"‚úÖ PASS: Image loaded\")\n",
        "\n",
        "    # Check 2: Grayscale conversion\n",
        "    try:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        print(f\"‚úÖ PASS: Grayscale conversion (shape: {gray.shape})\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå FAIL: Grayscale conversion - {e}\")\n",
        "        return\n",
        "\n",
        "    # Check 3: Contrast\n",
        "    contrast = gray.max() - gray.min()\n",
        "    print(f\"{'‚úÖ PASS' if contrast > 50 else '‚ö†Ô∏è  WARN'}: Contrast = {contrast} (need > 50)\")\n",
        "\n",
        "    # Check 4: Edge detection\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blur, my_threshold1, my_threshold2)\n",
        "    edge_pixels = np.sum(edges > 0)\n",
        "    edge_percent = (edge_pixels / edges.size) * 100\n",
        "    print(f\"{'‚úÖ PASS' if edge_percent > 1 else '‚ö†Ô∏è  WARN'}: Edges = {edge_percent:.2f}% (need > 1%)\")\n",
        "\n",
        "    # Check 5: ROI\n",
        "    height, width = edges.shape\n",
        "    vertices = np.array([[\n",
        "        (0, height),\n",
        "        (width//2 - 50, height//2 + 50),\n",
        "        (width//2 + 50, height//2 + 50),\n",
        "        (width, height)\n",
        "    ]], dtype=np.int32)\n",
        "    roi_edges = region_of_interest(edges, vertices)\n",
        "    roi_edge_pixels = np.sum(roi_edges > 0)\n",
        "    print(f\"{'‚úÖ PASS' if roi_edge_pixels > 500 else '‚ö†Ô∏è  WARN'}: ROI edges = {roi_edge_pixels} (need > 500)\")\n",
        "\n",
        "    # Check 6: Line detection\n",
        "    lines = detect_lines(roi_edges)\n",
        "    line_count = len(lines) if lines is not None else 0\n",
        "    print(f\"{'‚úÖ PASS' if line_count > 0 else '‚ùå FAIL'}: Lines detected = {line_count}\")\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if line_count == 0:\n",
        "        print(\"\\nüí° SUGGESTIONS:\")\n",
        "        if edge_percent < 1:\n",
        "            print(\"  - Lower Canny thresholds (try 30, 90)\")\n",
        "        if roi_edge_pixels < 500:\n",
        "            print(\"  - Adjust ROI to better cover lanes\")\n",
        "            print(\"  - Or lower Canny thresholds\")\n",
        "        print(\"  - Try lower Hough threshold (try 30)\")\n",
        "\n",
        "# Run diagnostics\n",
        "check_pipeline_health(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WavngIJu3IRp"
      },
      "source": [
        "---\n",
        "## Template 6: Save Your Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKUlDVIZ3IRp"
      },
      "outputs": [],
      "source": [
        "# Save Processed Images\n",
        "\n",
        "from google.colab import files as colab_files\n",
        "\n",
        "# Save your final result\n",
        "result_filename = 'lane_detection_result.jpg'\n",
        "cv2.imwrite(result_filename, result)\n",
        "\n",
        "# Download the file\n",
        "colab_files.download(result_filename)\n",
        "\n",
        "print(f\"‚úÖ Saved and downloading: {result_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7cdzGeX3IRp"
      },
      "outputs": [],
      "source": [
        "# Export Your Working Parameters\n",
        "\n",
        "# Create a text file with your parameters\n",
        "params_text = f\"\"\"\n",
        "MY WORKING PARAMETERS - Session 3\n",
        "=================================\n",
        "\n",
        "Image: {filename}\n",
        "Resolution: {img.shape[1]}x{img.shape[0]}\n",
        "\n",
        "Gaussian Blur:\n",
        "  - Kernel: {my_blur_kernel}\n",
        "\n",
        "Canny Edge Detection:\n",
        "  - threshold1: {my_threshold1}\n",
        "  - threshold2: {my_threshold2}\n",
        "\n",
        "ROI Vertices:\n",
        "  - Bottom left: (0, {height})\n",
        "  - Top left: ({width//2 - 50}, {height//2 + 50})\n",
        "  - Top right: ({width//2 + 50}, {height//2 + 50})\n",
        "  - Bottom right: ({width}, {height})\n",
        "\n",
        "Hough Transform:\n",
        "  - threshold: 50\n",
        "  - minLineLength: 40\n",
        "  - maxLineGap: 100\n",
        "\n",
        "Notes:\n",
        "  - Edge pixels: {edge_pixels_tuned} ({edge_percent_tuned:.2f}%)\n",
        "  - Lines detected: {len(lines) if lines is not None else 0}\n",
        "\"\"\"\n",
        "\n",
        "# Save to file\n",
        "with open('my_parameters.txt', 'w') as f:\n",
        "    f.write(params_text)\n",
        "\n",
        "# Download\n",
        "colab_files.download('my_parameters.txt')\n",
        "\n",
        "print(\"‚úÖ Parameters saved and downloading!\")\n",
        "print(\"\\n\" + params_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UCFUZcC3IRp"
      },
      "source": [
        "---\n",
        "## Template 7: Bonus - Test on Multiple Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0hVG5Xk3IRp"
      },
      "outputs": [],
      "source": [
        "# Upload Multiple Images\n",
        "\n",
        "print(\"Upload multiple test images:\")\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "print(f\"\\n‚úÖ Uploaded {len(uploaded_files)} images\")\n",
        "for filename in uploaded_files.keys():\n",
        "    print(f\"  - {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvHj9No83IRp"
      },
      "outputs": [],
      "source": [
        "# Batch Process All Images\n",
        "\n",
        "results = {}\n",
        "\n",
        "for filename in uploaded_files.keys():\n",
        "    print(f\"\\nProcessing: {filename}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Load image\n",
        "    img_test = cv2.imdecode(np.frombuffer(uploaded_files[filename], np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "    if img_test is None:\n",
        "        print(f\"‚ùå Could not load {filename}\")\n",
        "        continue\n",
        "\n",
        "    # Apply pipeline with your tuned parameters\n",
        "    result_test = lane_detection_pipeline(\n",
        "        img_test,\n",
        "        canny_low=my_threshold1,\n",
        "        canny_high=my_threshold2\n",
        "    )\n",
        "\n",
        "    # Store result\n",
        "    results[filename] = result_test\n",
        "\n",
        "    # Display\n",
        "    if result_test is not None:\n",
        "        show_image(result_test, f\"Result: {filename}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Processed {len(results)} images successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b59nBB3IRp"
      },
      "source": [
        "---\n",
        "\n",
        "You've completed the Computer Vision lab and built a working lane detection system.\n",
        "\n",
        "**Remember to:**\n",
        "1. Download your parameters file (Template 6)\n",
        "2. Save this notebook: File > Download > Download .ipynb\n",
        "3. Test your detector on different images\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zVPkuXmSxx0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}